{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WorkingGround\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from StringIO import StringIO\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib2,base64\n",
    "import cPickle as pickle\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from __future__ import division\n",
    "from vincenty import vincenty\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import geoplotlib as gp\n",
    "import scipy as sp\n",
    "import gdal \n",
    "from gdalconst import * \n",
    "import datetime\n",
    "import math\n",
    "import operator\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import requests, time\n",
    "import urllib, json\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "tls.set_credentials_file(username='ShawnHou', api_key='OohmqCJaPfb6p6xo4pDF')\n",
    "from geoplotlib.utils import BoundingBox\n",
    "from sklearn import neighbors, datasets,linear_model,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import LeavePLabelOut\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from pylab import *\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from urllib2 import urlopen, Request\n",
    "from pprint import pprint\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import MarkerCluster\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from pushover import init, Client\n",
    "from scipy.spatial import KDTree\n",
    "from calendar import monthrange\n",
    "from sklearn import metrics\n",
    "import tarfile\n",
    "\n",
    "#for parallel processing\n",
    "from ipyparallel import Client\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years_stat=dict()\n",
    "for YEAR in range(2017,1979,-1):\n",
    "    year_file=os.getcwd()+'\\\\data\\\\data option one\\\\'+str(YEAR)+'.csv.gz'\n",
    "    year_df = pd.read_csv(year_file, compression='gzip', header=None,usecols = used_columns,\n",
    "                              dtype=dict(zip(used_columns, dtypes)),sep=',').rename(columns=dict(zip(used_columns, data_columns)))\n",
    "    #year_station=year_df[ year_df['GHCND'].isin(temp_stations_clean['GHCND'].tolist())\n",
    "                                 #   & ( year_df['ATTRIBUTE'].isin([metric])) & ( year_df['VALUE']!=-999) ]\n",
    "    year_station_df=pd.merge(year_df,temp_stations_clean, how='right', on=\"GHCND\")\n",
    "    grouped_year_station= year_station_df.groupby(['ATTRIBUTE'])\n",
    "    for name, group in grouped_year_station:\n",
    "        group_sup_df=group[['GHCND','DATE','VALUE','LAT','LON','ELEV','ST']]\n",
    "        if name in wanted_metrics:\n",
    "            group_sup_df.to_csv('data\\\\daily GHCND dataframes\\\\{}.csv'.format(str(YEAR)+\"_\"+name),header=False, index_label=False)\n",
    "    #years_stat[YEAR]=year_station_df\n",
    "    print 'Year: ',YEAR, ' - ', year_station_df.info()\n",
    "    print \"***********************************************************************\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include outliner, size: (56918, 6)\n",
      "exclude outliner, size: (56911, 6)\n"
     ]
    }
   ],
   "source": [
    "temp_stations = pd.read_csv(os.getcwd()+'\\\\data\\\\data option one\\\\weather_station_list.csv',skipinitialspace=True)\n",
    "temp_stations['GHCND']=temp_stations.GHCND.str.strip()\n",
    "temp_stations=temp_stations[temp_stations.GHCND.str.contains(\"US\")] ##Discard non US stations\n",
    "temp_stations_clean=temp_stations[np.abs(temp_stations.LON-temp_stations.LON.mean())<=(5*temp_stations.LON.std())] ##discard OUTLIER by location\n",
    "\n",
    "print \"include outliner, size:\",temp_stations.shape\n",
    "print \"exclude outliner, size:\",temp_stations_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid reexecuting following section !!!! Due to connection to remote web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year=\"2016\"\n",
    "url_base = \"http://data.fcc.gov/api/block/find?\"\n",
    "county_fips=list()\n",
    "county_names=list()\n",
    "block_fips=list()\n",
    "print temp_stations_clean.shape\n",
    "i=0\n",
    "for index, row in temp_stations_clean.iterrows():\n",
    "    lat=str(row['LAT'])\n",
    "    lon=str(row['LON'])\n",
    "    url_geo=\"latitude=\"+lat+\"&\"+\"longitude=\"+lon+\"&format=json\"\n",
    "    url=url_base+url_geo\n",
    "    response = urllib.urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    county_fips.append(data['County']['FIPS'])\n",
    "    county_names.append(data['County']['name'])\n",
    "    block_fips.append(data['Block']['FIPS'])\n",
    "    i=i+1\n",
    "    if i%1000==0:\n",
    "        print i\n",
    "    if i%15000==0:\n",
    "        time.sleep(600)\n",
    "        \n",
    "\n",
    "county_fips_s = pd.Series(county_fips)\n",
    "county_name_s = pd.Series(county_names)\n",
    "block_fips_s = pd.Series(block_fips)\n",
    "temp_stations_clean['COUNTY_CODE'] = county_fips_s.values\n",
    "temp_stations_clean['COUNTY_NAME'] = county_name_s.values\n",
    "temp_stations_clean['BLOCK_CODE'] = block_fips_s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_stations_clean.to_csv('data\\\\daily dataframe\\\\cleaned_weather_station_list_withCounty.csv', index=False,encoding=\"UTF-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
